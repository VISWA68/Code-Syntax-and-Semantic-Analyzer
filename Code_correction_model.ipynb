{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z8MJAbAK2CE"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZigGJluHlM11"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.30.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "qoXgEDAn4d16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPp5mxBrK-zg"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLTmXTP6ML-L"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"code_x_glue_cc_code_refinement\",'small')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3wvoCaPMcEN"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaTokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tn-5mqRrMgEj"
      },
      "outputs": [],
      "source": [
        "def preprocess(example):\n",
        "    input_text = \"fix: \" + example['buggy']\n",
        "    target_text = example['fixed']\n",
        "    model_input = tokenizer(input_text, max_length=128, padding=\"max_length\", truncation=True)\n",
        "    label = tokenizer(target_text, max_length=128, padding=\"max_length\", truncation=True)\n",
        "    model_input[\"labels\"] = label[\"input_ids\"]\n",
        "    return model_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBxkDM79MkuO"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = dataset.map(preprocess, remove_columns=dataset[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE7DBlwtkTNs"
      },
      "outputs": [],
      "source": [
        "tokenized_train = tokenized_dataset[\"train\"].select(range(1000))\n",
        "tokenized_eval = tokenized_dataset[\"validation\"].select(range(200))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW0hvrnWMmtW"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./codet5-fix-model\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=None,\n",
        "    remove_unused_columns=False,\n",
        "    gradient_accumulation_steps=4,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAYJKi93M3t2"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXixqKC3M95p"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./codet5-fix-model\")\n",
        "tokenizer.save_pretrained(\"./codet5-fix-model\")\n"
      ],
      "metadata": {
        "id": "-u1ttwj07coe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, RobertaTokenizer\n",
        "\n",
        "model_path = \"./codet5-fix-model\"\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "PFPMKMnT-1Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_code(buggy_code):\n",
        "    input_text = \"fix: \" + buggy_code\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_length=512)\n",
        "\n",
        "    fixed_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return fixed_code\n",
        "\n",
        "buggy = \"def add(a,b):\\nreturn a+b\"\n",
        "fixed = fix_code(buggy)\n",
        "print(\"Fixed Code:\\n\", fixed)\n"
      ],
      "metadata": {
        "id": "9kOOmlaP-6rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, RobertaTokenizer\n",
        "\n",
        "model_path = \"./codet5-fix-model\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"Salesforce/codet5-base\")\n",
        "\n",
        "buggy_code = \"public static boolean isEmpty(String str) { return str.length() == 0; }\"\n",
        "input_text = \"fix: \" + buggy_code\n",
        "\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_length=128,\n",
        "    num_return_sequences=1,\n",
        "    num_beams=5,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "\n",
        "fixed_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"ðŸ”§ Fixed Code:\\n\" + fixed_code.strip())"
      ],
      "metadata": {
        "id": "dtCx-4DkKoaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"/content/codet5_model.zip\")\n"
      ],
      "metadata": {
        "id": "sOpVIWtuLMtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"/content/codet5_model\", 'zip', './codet5-fix-model')\n"
      ],
      "metadata": {
        "id": "jUnDITvRPQv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"code_x_glue_cc_code_refinement\", \"small\")\n",
        "\n",
        "print(\"Available splits:\", dataset.keys())\n",
        "\n",
        "print(\"\\nExample from train split:\")\n",
        "print(dataset['train'][0])\n",
        "\n",
        "print(\"\\nExample from validation split:\")\n",
        "print(dataset['validation'][0])\n",
        "\n",
        "print(\"\\nExample from test split:\")\n",
        "print(dataset['test'][0])\n"
      ],
      "metadata": {
        "id": "RygIXUvePgiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Ux8KcgLUdzOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kbI60THnd2px"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}